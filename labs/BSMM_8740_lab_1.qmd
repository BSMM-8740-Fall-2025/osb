---
title: "Lab 1 - Tidy Data Wrangling"
editor: visual
reference-location: margin
---

## Introduction

This lab will go through many of the same operations we've demonstrated in class. The main goal is to reinforce our understanding of tidy data, the tidyverse and the pipe, which we will be using throughout the course.

As the labs progress, you are encouraged to explore beyond what the labs require; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R and the tidyverse. Today we begin with exercises in the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.

### Learning goals

By the end of the lab, you will...

-   Have practiced version control using GitHub
-   Be familiar with the workflow using R, RStudio, Git, and GitHub

::: callout-important
To access Github from the lab, you will need to make sure you are logged in as follows:

-   username: **.\\daladmin**
-   password: **Business507!**
:::

# Now, today's lab

We will use the following package in today's lab.

::: callout-note
The code below will install (if necessary) and load the packages needed in today's exercises
:::

```{r}
#| message: false
#| error: false
# check if 'librarian' is installed and if not, install it
if (! "librarian" %in% rownames(installed.packages()) ){
  install.packages("librarian")
  
# load packages if not already loaded
librarian::shelf(tidyverse, Lahman, magrittr, gt, gtExtras, ggplot2)}
```

The tidyverse is a meta-package. When you load it you get eight packages loaded for you:

-   **ggplot2**: for data visualization
-   **dplyr**: for data wrangling
-   **tidyr**: for data tidying and rectangling
-   **readr**: for reading and writing data
-   **tibble**: for modern, tidy data frames
-   **stringr**: for string manipulation
-   **forcats**: for dealing with factors
-   **purrr**: for iteration with functional programming

The message that's printed when you load the package tells you which versions of these packages are loaded as well as any conflicts they may have introduced, e.g., the `filter()` function from dplyr has now masked (overwritten) the `filter()` function available in base R (and that's ok, we'll use `dplyr::filter()` anyway).

We'll be using functionality from all of these packages throughout the semester, though we'll always load them all at once with `library(tidyverse)`. You can find out more about the tidyverse and each of the packages that make it up [here](https://www.tidyverse.org/).

## Data: Yearly statistics and standings for baseball teams

Today's data is all baseball statistics. The data is in the `Lahman` package.

### View the data

Before doing any analysis, you may want to get quick view of the data. This is useful when you've imported data to see if your data imported correctly. We can use the `view()` function to see the entire data set in RStudio. Type the code below in the **Console** to view the entire dataset.

```{r}
#| eval: false
dim(Teams)
```

## Data dictionary

The variable definitions are found in the help for Teams

```{r}
#| eval: false
?Teams
```

### Exercises

Write all code and narrative in your R Markdown file. Write all narrative in complete sentences. Throughout the assignment, you should periodically **Render** your Quarto document to produce the updated PDF, **commit** the changes in the Git pane, and **push** the updated files to GitHub.

::: callout-tip
Make sure we can read all or your code in your PDF document. This means you will need to break up long lines of code. One way to help avoid long lines of code is is start a new line after every pipe (`%>%`) and plus sign (`+`).
:::

### Exercise 1

The `view()` function helped us get a quick view of the dataset, but let's get more detail about its structure. Viewing a summary of the data is a useful starting point for data analysis, especially if the dataset has a large number of observations (rows) or variables (columns). Run the code below to use the `dplyr::glimpse()` function to see a summary of the `ikea` dataset.

How many observations are in the `ikea` dataset? How many variables?

```{r}
#| eval: false
#| label: glimpse-data
#| results: false
dplyr::glimpse(Teams)
```

::: callout-note
In your `lab-1.qmd` document you'll see that we already added the code required for the exercise as well as a sentence where you can fill in the blanks to report the answer. Use this format for the remaining exercises.

Also note that the code chunk as a label: `glimpse-data`. It's not required, but good practice and highly encouraged to label your code chunks in this way.
:::

### Exercise 2

[Ben Baumer](#0) worked for the [New York Mets](#0) from 2004 to 2012. What was the team W/L record during those years? Use `filter()` and `select()` to quickly identify only those pieces of information that we care about.

```{r}
#| eval: false
mets <- Teams  %>% 
  dplyr::filter(teamID == "NYN")
my_mets <- mets %>% 
  dplyr::filter(_)
my_mets %>% 
  dplyr::select(_,_,_,_)
```

### Exercise 3

We've answered the simple question of how the Mets performed during the time that Ben was there, but since we are data scientists, we are interested in deeper questions. For example, some of these seasons were subpar---the Mets had more losses than wins. Did the team just get unlucky in those seasons? Or did they actually play as badly as their record indicates?

In order to answer this question, we need a model for expected winning percentage. It turns out that one of the most widely used contributions to the field of baseball analytics (courtesy of [Bill James](https://en.wikipedia.org/w/index.php?search=Bill%20James)) is exactly that. This model translates the number of runs^[4](https://mdsr-book.github.io/mdsr3e/04-dataI.html?s=03#fn4)^ that a team scores and allows over the course of an entire season into an expectation for how many games they should have won. The simplest version of this model is this:

$$
\hat{\text{W}}_{\text{pct}}=\frac{1}{1+\left(\frac{\text{RA}}{\text{RS}}\right)^{2}}
$$

where $\text{RA}$ is the number of runs the team allows to be scored, $\text{RS}$ is the number of runs that the team scores, and $\hat{\text{W}}_{\text{pct}}$ is the team's expected winning percentage. Luckily for us, the runs scored and allowed are present in the `Teams` table, so let's grab them and save them in a new data frame.

```{r}
#| eval: false
mets_ben <- Teams |>
  dplyr::select(_, _, _, _, _, _) |>
  dplyr::filter(_ == "NYN" & _ %in% 2004:2012)
mets_ben
```

First, note that the runs-scored variable is called `R` in the `Teams` table, but to stick with our notation we want to rename it `RS`.

```{r}
#| eval: false
mets_ben <- mets_ben |>
  dplyr::rename(_ = _)    # new name = old name
mets_ben
```

::: render-commit-push
This is a good place to fender, commit, and push changes to your remote bsmm-lab-1 repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you've made, write an informative commit message (e.g., "Completed exercises 1 - 3"), and push. After you push the changes, the Git pane in RStudio should be empty.
:::

### Exercise 4

Next, we need to compute the team's actual winning percentage in each of these seasons. Thus, we need to add a new column to our data frame, and we do this with the `mutate()` command.

```{r}
#| eval: false
mets_ben <- mets_ben |>
  dplyr::mutate(WPct = _)
mets_ben
```

The expected number of wins is then equal to the product of the expected winning percentage times the number of games.

```{r}
#| eval: false
mets_ben <- mets_ben |>
  dplyr::mutate(W_hat = _)
mets_ben
```

### Exercise 5

In this case, the Mets' fortunes were better than expected in three of these seasons, and worse than expected in the other six.

In how many seasons were the Mets better than expected? How many were they worse than expected?

::: render-commit-push
This is a good place to render, commit, and push changes to your remote lab-1 repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you've made, write an informative commit message (e.g., "Completed exercises 4 and 5"), and push. After you push the changes, the Git pane in RStudio should be empty.
:::

### Exercise 6

Naturally, the Mets experienced ups and downs during Ben's time with the team. Which seasons were best? To figure this out, we can simply sort the rows of the data frame.

```{r}
#| eval: false
dplyr::arrange(mets_ben, _)
```

### Exercise 7

In 2006, the Mets had the best record in baseball during the regular season and nearly made the [*World Series*](https://en.wikipedia.org/w/index.php?search=World%20Series). How do these seasons rank in terms of the team's performance relative to our model?

```{r}
#| eval: false
mets_ben %>% 
  dplyr::mutate(Diff = _) |>
  dplyr::arrange(_)
```

### Exercise 8

Summarize the Mets performance

```{r}
#| eval: false
mets_ben |>
  dplyr::summarize(
    num_years = _, 
    total_W = _, 
    total_L = _, 
    total_WPct = _, 
    sum_resid = _
  )
```

In these nine years, the Mets had a combined record of \_ wins and \_ losses, for an overall winning percentage of \_.

::: render-commit-push
This is a good place to render, commit, and push changes to your remote lab-1 repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you've made, write an informative commit message (e.g., "Completed exercises 6 - 8"), and push. After you push the changes, the Git pane in RStudio should be empty.
:::

### Exercise 9

Next, let's look at the relationship between the price and width of Ikea furniture. Fill in the code below to visualize the relationship between the two variables using a scatterplot.

Then, use your visualization to describe the relationship between the width and price of Ikea furniture.

```{r}
#| eval: false
ggplot(data = _____, aes(x = width, y = _____)) +
  geom_point() + 
  labs(
    x = "_____", 
    y = "_____", 
    title = "_____"
    )
```

### Exercise 10

Discretize the years into three chunks: one for each of the three general managers under whom Ben worked. [Jim Duquette](https://en.wikipedia.org/w/index.php?search=Jim%20Duquette) was the Mets' [*general manager*](https://en.wikipedia.org/w/index.php?search=general%20manager) in 2004, [Omar Minaya](https://en.wikipedia.org/w/index.php?search=Omar%20Minaya) from 2005 to 2010, and [Sandy Alderson](https://en.wikipedia.org/w/index.php?search=Sandy%20Alderson) from 2011 to 2012.

```{r}
#| eval: false
mets_ben <- mets_ben %>% 
  dplyr::mutate(
    gm = ifelse(
      yearID == _, 
      _, 
      ifelse(
        yearID >= _, 
        _, 
        _)
    )
  )

```

Alternatively, we use the `case_when` function

```{r}
#| eval: false
mets_ben <- mets_ben |>
  dplyr::mutate(
    gm = dplyr::case_when(
      yearID == _ ~ _, 
      yearID >= _ ~ _, 
      TRUE ~ _
    )
  )
```

::: render-commit-push
You're done and ready to submit your work! Render, commit, and push all remaining changes. You can use the commit message "Done with Lab 1!" , and make sure you have committed and pushed all changed files to GitHub (your Git pane in RStudio should be empty) and that **all** documents are updated in your repo on GitHub.
:::

### Exercise 11

#### The Business Problem

The story begins in a fast paced startup. The company is growing fast and the marketing team is looking for ways to increase the sales from existing customers by making them buy more. The main idea is to unlock the potential of the customer base through incentives, in this case a discount. We of course want to measure the effect of the discount on the customer's behavior. Still, they do not want to waste money giving discounts to users which are not valuable. As always, it is about return on investment (ROI). Without going into specifics about the nature of the discount, it has been designed to provide a positive return on investment if the customer buys more than $1\$$ as a result of the discount. How can we measure the effect of the discount and make sure our experiment has a positive ROI? The marketing team came up with the following strategy:

-   Select a sample of existing customers from the same cohort.
-   Set a test window of 1 month.
-   Look into the historical data of web visits from the last month. The hypothesis is that web visits are a good proxy for the customer's interest in the product.
-   For customers with a high number of web visits, send them a discount. There will be a hold out group which will not receive the discount within the potential valuable customers based on the number of web visits. For customers with a low number of web visits, do not send them a discount (the marketing team wants to report a positive ROI, so they do not want to waste money on customers which are not valuable). Still, they want to use them to measure the effect of the discount.
-   We also want to use the results of the test to tag *loyal* customers. These are customers which got a discount (since they showed potential interest in the product) and customers with exceptional sales numbers even if they did not get a discount. The idea is to use this information to target them in the future if the discount strategy is positive.

#### The Data

The team collected data from the experiment above and asked the data science team to analyze it and provide insights. In particular they want to know if they should keep the discount strategy. The data consists of the following fields: - `visits`: Number of visits to the website during the test window. - `discount`: Whether the customer received a discount or not. - `is_loyal`: Whether the customer is loyal or not according to the definition above. - `sales`: Sales in $\$$ during the test window.

##### Prepare Notebook

Data scientist A was the one in charge of preparing the environment and collecting the data. As an important best practice, they fixed a global seed which initializes the random number generator in order to make sure every part of the analysis was reproducible. This ensures that the calculations are not affected by pure randomness. In addition all the required packages were listed from the start (reproducible R environment).

```{r}
set.seed(8740)
```

##### Read Data

They pulled the data from a csv file and displayed the first 5 measurements.

```{r}
data <- readr::read_csv(here::here("labs/data", "sales_dag.csv"), show_col_types = FALSE)

data |> dplyr::slice_head(n=5) |> 
  gt::gt() |> 
  gt::tab_header(title = "sample marketing data") |> 
  gtExtras::gt_theme_espn()
```

They then checked for missing values and whether the measurements were in the correct format.

```{r}
# run a data exploration here

```

##### Exploratory Data Analysis

As part of the project scope, the data science team in charge of the analysis was asked to provide a summary of the data. The team was also asked to provide a visualization of the data to help the marketing team understand the data better. Data scientist A took over this task.

They started by looking at the share of customers which received a discount:

```{r}
# show the % share of customers receiving a discount vs the % ot receiving a discount
```

Similarly for the share of customers which are loyal:

```{r}
# show the % share of customers that are 'loyal' vs not 'loyal'
```

To understand these features better, they also looked at a cross-tab table:

```{r}
# build a cross-tab table of 'loyal' custmers vs customers getting a discount

```

Note that all customers with discount are loyal (as required) and that there are loyal users which did not receive a discount. This is because they had exceptional sales numbers. Verify this:

```{r}
#| eval: false
data |> dplyr::mutate(id = dplyr::row_number(), .before = 1) |> 
  dplyr::filter(discount == 0) |> 
  dplyr::arrange( desc(sales) ) |> 
  dplyr::slice_head(n=10) |> 
  gt::gt() |> 
  gt::tab_header(title = "Sales: loyal customers vs others") |> 
  gtExtras::gt_theme_espn()

```

The loyal customers are the top ones in terms of sales. This is good news. It means that the definition of loyal customers is consistent with the data.

In order to have orders of magnitude for the sales, the data scientist provided some summary statistics table:

```{r}
#| eval: false
#| warning: false
#| message: false
# data["sales"].describe()
gtExtras::gt_plt_summary(data)
```

To have a better glimpse of the data, the data scientist also provided a histogram of the sales:

```{r}
#| eval: false
#| warning: false
#| message: false

data |> 
  ggplot(aes(x=sales)) +
  geom_histogram(aes(y = ..density..), bins = 30, colour = 1, fill = "white") +
  geom_density(lwd = 1, colour = 4, fill = 4, alpha = 0.25) +
  labs(title = "Sales Distribution") +
  theme_minimal()
```

::: render-commit-push
## Submission

I will pull (copy) everyone's submissions at 5:00pm on the Friday following class, and I will work only with these copies, so anything submitted after 5:00pm will not be graded. (**don't forget to commit and then push your work!**)
:::

## Grading

Total points available: 30 points.

| Component | Points |
|-----------|--------|
| Ex 1 - 11 | 30     |

## Resources for additional practice (optional)

-   [Chapter 2: Get Started](https://socviz.co/gettingstarted.html#work-in-plain-text-using-rmarkdown) *Data Visualization by Kieran Healy*
-   [Chapter 3: Data visualization](https://r4ds.had.co.nz/data-visualisation.html) in *R for Data Science* by Hadley Wickham
-   RStudio Cloud Primers
    -   Visualization Basics: <https://rstudio.cloud/learn/primers/1.1>
    -   Work with Data: <https://rstudio.cloud/learn/primers/2>
    -   Visualize Data: <https://rstudio.cloud/learn/primers/3>
